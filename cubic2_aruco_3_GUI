import cv2
import tkinter as tk
from tkinter import Label, Button, Entry
from PIL import Image, ImageTk
import numpy as np
import csv
import math
import cv2
import tkinter as tk
from tkinter import Label, Button
from PIL import Image, ImageTk
import numpy as np
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import time
import smbus
from collections import deque
from scipy.spatial import cKDTree
from scipy.interpolate import splprep, splev
import sys
import select

from cv2 import aruco
#Aruco è®¾ç½®
ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_4X4_50)
ARUCO_PARAMS = aruco.DetectorParameters_create()

# I2C è®¾ç½®
bus = smbus.SMBus(1)
arduino_address = 0x08

def int16_to_bytes(val):
    val = int(val)
    if val < 0:
        val = (1 << 16) + val
    return [(val >> 8) & 0xFF, val & 0xFF]
'''
def send_two_points_16bit(x1, y1, x2, y2):
    data = int16_to_bytes(x1) + int16_to_bytes(y1) + int16_to_bytes(x2) + int16_to_bytes(y2)
    try:
        bus.write_i2c_block_data(arduino_address, 0x00, data)
        print(f"Sent: ({x1}, {y1}) -> ({x2}, {y2})")
    except Exception as e:
        print(f"I2C Send Error: {e}")
'''
def send_two_points_16bit(x1, y1, x2, y2):
    global last_send_time
    now = time.time()
    if now - last_send_time < SEND_INTERVAL:
        print(f"time out")
        return  # æ—¶é—´é—´éš”ä¸è¶³ï¼Œä¸å‘é€
    last_send_time = now  # æ›´æ–°æ—¶é—´æˆ³

    data = int16_to_bytes(x1) + int16_to_bytes(y1) + int16_to_bytes(x2) + int16_to_bytes(y2)
    try:
        bus.write_i2c_block_data(arduino_address, 0x00, data)
        print(f"Sent: ({x1}, {y1}) -> ({x2}, {y2})")
    except Exception as e:
        print(f"I2C Send Error: {e}")

# å‚æ•°
INTERPOLATION_COUNT = 2
headidx = 30
lower_red_1 = np.array([0, 120, 20])
upper_red_1 = np.array([10, 255, 120])
lower_red_2 = np.array([170, 120, 20])
upper_red_2 = np.array([180, 255, 120])
lower_black = np.array([0, 0, 0])
upper_black = np.array([180, 255, 50])
last_send_time = 0  # å…¨å±€å˜é‡ï¼Œè®°å½•ä¸Šæ¬¡å‘é€çš„æ—¶é—´æˆ³
SEND_INTERVAL = 0.04  # å‘é€é—´éš” 50 æ¯«ç§’
errors = []  # ç”¨äºä¿å­˜æ¯å¸§çš„è¯¯å·®å€¼
timestamps = []  # ä¿å­˜æ¯å¸§çš„æ—¶é—´æˆ³
history_points = deque(maxlen=300)  # çº¢çƒå†å²åæ ‡ï¼Œç”¨äºç”»è½¨è¿¹
nearest_points = []  # âœ… æ–°å¢è®°å½•æœ€è¿‘è·¯å¾„ç‚¹
aruco_corners_dict = {}  # ç”¨äºå­˜å‚¨å››ä¸ªArUco markerçš„è§’ç‚¹
aruco_roi_list = [] #ArUco ROIåˆå§‹åŒ–
aruco_centers_dict = {}  # ç”¨äºä¿å­˜æ¯ä¸ª ArUco ID çš„ä¸­å¿ƒç‚¹åæ ‡
last_red_center = None
x__1 = 0
x__2 = 0
y__1 = 0
y__2 = 0

# å®æ—¶è¯†åˆ«çº¢çƒä½ç½®
# å®æ—¶è¯†åˆ«çº¢çƒä½ç½®
def detect_red_ball(frame):
    global last_red_center
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # é»˜è®¤ä½¿ç”¨æ•´å¼ å›¾åƒ
    h, w = frame.shape[:2]
    roi_margin = 60

    if last_red_center:
        yc, xc = last_red_center
        y_min = max(0, yc - roi_margin)
        y_max = min(h, yc + roi_margin)
        x_min = max(0, xc - roi_margin)
        x_max = min(w, xc + roi_margin)

        roi_hsv = hsv[y_min:y_max, x_min:x_max]
        red_mask = cv2.bitwise_or(
            cv2.inRange(roi_hsv, lower_red_1, upper_red_1),
            cv2.inRange(roi_hsv, lower_red_2, upper_red_2)
        )
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        max_area = 0
        best_center = None
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area > 100 and area > max_area:
                x, y, w_box, h_box = cv2.boundingRect(cnt)
                best_center = (y + h_box // 2 + y_min, x + w_box // 2 + x_min)  # åŠ åç§»
                max_area = area

        if best_center is not None:
            last_red_center = best_center
            return best_center

    # Fallbackï¼šæ•´å›¾æŸ¥æ‰¾
    red_mask = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red_1, upper_red_1),
        cv2.inRange(hsv, lower_red_2, upper_red_2)
    )
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    max_area = 0
    best_center = None
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 100 and area > max_area:
            x, y, w_box, h_box = cv2.boundingRect(cnt)
            best_center = (y + h_box // 2, x + w_box // 2)
            max_area = area

    if best_center is not None:
        last_red_center = best_center
    return best_center

def calculate_distance(pt1, pt2):
    return math.hypot(pt1[0] - pt2[0], pt1[1] - pt2[1])


# è·¯å¾„å›¾å±‚å‡½æ•°
def generate_path_overlay(image):
    '''
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    
    selected_path_image = np.zeros_like(image)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        perimeter = cv2.arcLength(cnt, True)

        # === æ´å£è¿‡æ»¤é€»è¾‘ ===
        if area > 2000:  # è·³è¿‡å¤ªå¤§çš„åŒºåŸŸï¼Œé¿å…è¯†åˆ«åˆ°æ´
            continue
        if cv2.isContourConvex(cnt):  # è·³è¿‡é—­åˆç¯
            continue

        if 50 < area < 1500 and perimeter > 80:
            approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)
            if len(approx) > 5:
                cv2.drawContours(selected_path_image, [cnt], -1, (255, 255, 255), 2)
    
  
    # éª¨æ¶æå–
    gray_selected = cv2.cvtColor(selected_path_image, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray_selected, 127, 255, cv2.THRESH_BINARY)
    skeleton = cv2.ximgproc.thinning(binary)
    non_zero_points = np.column_stack(np.where(skeleton > 0))
    '''
    global aruco_corners_dict

    # åŸºäºé¢œè‰²çš„é»‘çº¿æ©è†œæå–è·¯å¾„ï¼ˆé¿å…è¯†åˆ«åˆ°æ´ï¼‰    
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    black_mask = cv2.inRange(hsv, lower_black, upper_black)
    black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))

    # éª¨æ¶æå–ï¼ˆé»‘çº¿ç»†åŒ–ï¼‰
    skeleton = cv2.ximgproc.thinning(black_mask)
    non_zero_points = np.column_stack(np.where(skeleton > 0))

    # çº¢çƒæ£€æµ‹
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    red_mask = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red_1, upper_red_1),
        cv2.inRange(hsv, lower_red_2, upper_red_2)
    )
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    red_center = None
    max_area = 0
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 100 and area > max_area:
            x, y, w, h = cv2.boundingRect(cnt)
            red_center = (y + h // 2, x + w // 2)
            max_area = area

    # fallback èµ·ç‚¹ï¼šè‹¥æœªè¯†åˆ«çº¢çƒï¼Œåˆ™ä½¿ç”¨å›¾åƒä¸­å¿ƒæœ€è¿‘çš„éª¨æ¶ç‚¹
    if red_center is None:
        print("âš ï¸ æœªæ£€æµ‹åˆ°çº¢çƒï¼Œè‡ªåŠ¨ä½¿ç”¨è·¯å¾„éª¨æ¶ä¸Šçš„ç‚¹ä½œä¸ºèµ·ç‚¹")
        if len(non_zero_points) == 0:
            return image.copy(), None, []
        center_yx = np.array([image.shape[0] // 2, image.shape[1] // 2])
        distances = np.linalg.norm(non_zero_points - center_yx, axis=1)
        nearest_idx = np.argmin(distances)
        red_center = tuple(non_zero_points[nearest_idx])

    # ç¨€ç–åŒ–éª¨æ¶ç‚¹
    kdtree = cKDTree(non_zero_points)
    placed_points, used_indices = [], set()
    for idx, point in enumerate(non_zero_points):
        if idx not in used_indices:
            placed_points.append(point)
            used_indices.update(kdtree.query_ball_point(point, r=10))
    placed_points = np.array(placed_points)

    # ä»çº¢çƒèµ·ç‚¹å‡ºå‘æ„å»ºæœ‰åºè·¯å¾„
    all_points = placed_points.tolist()
    ordered_path = [red_center]
    used = set()
    current_point = red_center
    kdtree_path = cKDTree(all_points)

    while True:
        distances, indices = kdtree_path.query(current_point, k=len(all_points))
        next_point = None
        for idx in indices:
            candidate = tuple(all_points[idx])
            #if candidate not in used and calculate_distance(current_point, candidate) < 65:
            if candidate not in used and calculate_distance(current_point, candidate) < 120:
                next_point = candidate
                break
        if next_point is None:
            break
        ordered_path.append(next_point)
        used.add(next_point)
        current_point = next_point

    # æ’å€¼ç”Ÿæˆ refined_path
    refined_path = []
    for i in range(len(ordered_path) - 1):
        p1 = np.array(ordered_path[i])
        p2 = np.array(ordered_path[i + 1])
        refined_path.append(tuple(p1))
        for j in range(1, INTERPOLATION_COUNT + 1):
            ratio = j / (INTERPOLATION_COUNT + 1)
            new_point = tuple(((1 - ratio) * p1 + ratio * p2).astype(int))
            refined_path.append(new_point)
    refined_path.append(tuple(ordered_path[-1]))

    # âœ… âœ… âœ… åœ¨è¿™é‡Œæ’å…¥ spline å¹³æ»‘éƒ¨åˆ† âœ… âœ… âœ…
    if len(refined_path) >= 4:
        try:
            path_array = np.array(refined_path)
            y_points, x_points = path_array[:, 0], path_array[:, 1]

            from scipy.interpolate import splprep, splev
            tck, u = splprep([x_points, y_points], s=1000, k=3)
            u_fine = np.linspace(0, 1, len(refined_path) * 5)
            x_smooth, y_smooth = splev(u_fine, tck)
            refined_path = [(int(y), int(x)) for x, y in zip(x_smooth, y_smooth)]
        except Exception as e:
            print(f"âš ï¸ Bæ ·æ¡æ‹Ÿåˆå¤±è´¥ï¼Œä¿ç•™åŸå§‹æ’å€¼è·¯å¾„ã€‚åŸå› : {e}")
    else:
        print("âš ï¸ è·¯å¾„ç‚¹æ•°ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œ Bæ ·æ¡å¹³æ»‘")

    # âœ… ä¿ç•™è·¯å¾„å¯è§†åŒ–
    overlay = image.copy()
    for i in range(len(refined_path) - 1):
        cv2.line(overlay, (refined_path[i][1], refined_path[i][0]),
                      (refined_path[i + 1][1], refined_path[i + 1][0]), (0, 255, 255), 1)

    # === [ArUco æ£€æµ‹é€»è¾‘ï¼Œå¹¶ä¸”è®¾ç½®å››ä¸ªROI]  ===
    aruco_roi_list.clear()#æ¸…ç†å¯èƒ½æ®‹ç•™çš„ROIä¿¡æ¯
    margin = 80 #è®¾ç½®æ§åˆ¶ç”¨äºæ£€æµ‹ArUcoçš„ROIå¤§å°çš„å˜é‡
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)
    if ids is None:
        print("è·¯çº¿æ£€æµ‹æ—¶æ²¡æœ‰æ£€æµ‹åˆ° ä»»ä½•ArUco")
        return overlay, red_center, refined_path
    else:
        for i, marker_id in enumerate(ids.flatten()):
            if 0 <= marker_id <= 3:
                pts = corners[i][0]  # shape: (4, 2)
                aruco_corners_dict[marker_id] = pts
                x_min = max(0, int(np.min(pts[:, 0])) - margin)
                x_max = min(image.shape[1], int(np.max(pts[:, 0])) + margin)
                y_min = max(0, int(np.min(pts[:, 1])) - margin)
                y_max = min(image.shape[0], int(np.max(pts[:, 1])) + margin)
                aruco_roi_list.append((marker_id, (x_min, x_max, y_min, y_max)))

    if len(aruco_roi_list) < 4:
        print("âš ï¸ æ£€æµ‹åˆ°çš„ ArUco ä¸å®Œæ•´ï¼Œå¯èƒ½ä¸åŒ…å«å…¨éƒ¨ 0~3")
    else:
        print("âœ… åˆå§‹ ArUco ROI åŒºåŸŸæå–å®Œæˆ") 

    if ids is not None:
        aruco.drawDetectedMarkers(overlay, corners, ids)
        for i, marker_id in enumerate(ids.flatten()):
            pts = corners[i][0]
            cx = int(np.mean(pts[:, 0]))
            cy = int(np.mean(pts[:, 1]))
            cv2.circle(overlay, (cx, cy), 4, (0, 255, 0), -1)
            cv2.putText(overlay, f"ID: {marker_id}", (cx + 10, cy - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return overlay, red_center, refined_path
#å°†å››ä¸ªè§’åæ ‡è½¬æ¢ä¸ºä¸­å¿ƒåæ ‡
def get_aruco_centers(aruco_corners_dict):
    global aruco_centers_dict
    aruco_centers_dict.clear()
    for marker_id, corners in aruco_corners_dict.items():
        center = np.mean(corners, axis=0)
        aruco_centers_dict[marker_id] = tuple(center)

#ç”Ÿæˆ H çŸ©é˜µ åŠ å…¥ä¸­å¿ƒç‚¹è½¬åŒ–
def compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17)):
    if len(aruco_centers_dict) < 4:
        print("âš ï¸ ArUco ä¸­å¿ƒç‚¹ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆ H çŸ©é˜µ")
        return None

    # 1. æå–å››ä¸ª marker ä¸­å¿ƒç‚¹ï¼ˆæŒ‰ç…§ä½ æŒ‡å®šçš„é¡ºåºï¼‰
    try:
        src_pts = np.array([
            aruco_centers_dict[0],
            aruco_centers_dict[1],
            aruco_centers_dict[2],
            aruco_centers_dict[3]
        ], dtype=np.float32)
    except KeyError as e:
        print(f"âš ï¸ ç¼ºå¤± ArUco {e}ï¼Œè¯·ç¡®è®¤0~3å…¨éƒ¨è¯†åˆ«åˆ°äº†")
        return None

    # 2. å®šä¹‰ç›®æ ‡åæ ‡ç‚¹ï¼ˆä½ å¸Œæœ›ä»–ä»¬å¯¹åº”çš„ä½ç½®ï¼Œæ¯”å¦‚ä¸€ä¸ª 400x400 çš„æ£‹ç›˜ï¼‰
    dst_pts = np.array([
        [-(target_size[0]/2), (target_size[1]/2)],             # ArUco 0 â†’ å·¦ä¸Šè§’
        [(target_size[0]/2), (target_size[1]/2)],       # ArUco 1 â†’ å³ä¸Šè§’
        [(target_size[0]/2), -(target_size[1]/2)], # ArUco 2 â†’ å³ä¸‹è§’
        [-(target_size[0]/2), -(target_size[1]/2)]        # ArUco 3 â†’ å·¦ä¸‹è§’
    ], dtype=np.float32)

    # 3. è®¡ç®— Homography
    H = cv2.getPerspectiveTransform(src_pts, dst_pts)
    return H
#å®æ—¶æ£€æµ‹ARUCOçš„ä½ç½®ï¼ˆå››ä¸ª ROI ä¸­çš„ ï¼‰
def detect_aruco_and_update(frame):
    global aruco_corners_dict, aruco_centers_dict, aruco_roi_list
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # å¦‚æœ ROI åŒºåŸŸå­˜åœ¨ï¼Œå…ˆè¿›è¡Œ ROI è£å‰ªå¹¶åªåœ¨è¯¥åŒºåŸŸæ£€æµ‹
    if aruco_roi_list:
        for roi in aruco_roi_list:
            marker_id, (x_min, x_max, y_min, y_max) = roi
            roi_frame = gray[y_min:y_max, x_min:x_max]
            corners, ids, _ = aruco.detectMarkers(roi_frame, ARUCO_DICT, parameters=ARUCO_PARAMS)

            # æ£€æµ‹åˆ° ArUco marker åæ›´æ–°å­—å…¸
            if ids is not None:
                for i, marker_id in enumerate(ids.flatten()):
                    if 0 <= marker_id <= 3:
                        pts = corners[i][0] + np.array([x_min, y_min])  # æ·»åŠ  ROI åç§»
                        aruco_corners_dict[marker_id] = pts
                        center = np.mean(pts, axis=0)
                        aruco_centers_dict[marker_id] = tuple(center)

        print(f"ğŸ” å®æ—¶æ£€æµ‹åˆ° ArUco ID: {list(aruco_corners_dict.keys())}")
    else:
        # å¦‚æœæ²¡æœ‰ ROIï¼Œç›´æ¥åœ¨æ•´ä¸ªå›¾åƒä¸Šè¿›è¡Œæ£€æµ‹
        corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)

        if ids is not None:
            aruco_corners_dict.clear()
            aruco_centers_dict.clear()
            for i, marker_id in enumerate(ids.flatten()):
                if 0 <= marker_id <= 3:
                    pts = corners[i][0]
                    aruco_corners_dict[marker_id] = pts
                    center = np.mean(pts, axis=0)
                    aruco_centers_dict[marker_id] = tuple(center)
            print(f"ğŸ” å®æ—¶æ£€æµ‹åˆ° ArUco ID: {list(aruco_corners_dict.keys())}")
        else:
            print("âš ï¸ å®æ—¶æœªæ£€æµ‹åˆ°ä»»ä½• ArUco")

#ä½¿ç”¨è¯†åˆ«å‡ºæ¥çš„ArUcoè¿›è¡Œå°çƒåæ ‡è¿˜åŸ            
def detect_aruco_and_map_red_ball(red_center, frame):
    """
    å·²çŸ¥çº¢çƒå›¾åƒåæ ‡ red_centerï¼Œ
    è‡ªåŠ¨æ£€æµ‹ ArUco markerã€è®¡ç®— H çŸ©é˜µï¼Œå¹¶å°† red_center æ˜ å°„åˆ° ArUco å¹³é¢åæ ‡ç³»ä¸­ã€‚
    
    å‚æ•°ï¼š
        red_center: tuple(int, int)ï¼Œå›¾åƒåæ ‡ä¸‹çš„çº¢çƒä½ç½® (y, x)
        frame: å½“å‰å›¾åƒå¸§
    
    è¿”å›ï¼š
        real_world_red_center: tuple(float, float)ï¼Œæ˜ å°„åˆ° ArUco å¹³é¢åæ ‡ç³»çš„åæ ‡ (x, y)
    """
    if red_center is None:
        print("âš ï¸ è¾“å…¥çš„ red_center ä¸ºç©ºï¼Œè·³è¿‡")
        return None

    # 1. å®æ—¶æ£€æµ‹ ArUco marker å¹¶æ›´æ–° ROI å’Œè§’ç‚¹å­—å…¸
    detect_aruco_and_update(frame)

    # 2. è·å–ä¸­å¿ƒç‚¹
    get_aruco_centers(aruco_corners_dict)

    # 3. è®¡ç®— Homography çŸ©é˜µ
    H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
    if H is None:
        print("âŒ æ— æ³•è®¡ç®— Homographyï¼Œè¿”å› None")
        return None

    # 4. å°†çº¢çƒå›¾åƒåæ ‡è½¬æ¢ä¸º ArUco å¹³é¢åæ ‡ç³»
    point_arr = np.array([[[red_center[1], red_center[0]]]], dtype=np.float32)  # æ³¨æ„é¡ºåº x, y
    projected = cv2.perspectiveTransform(point_arr, H)
    real_world_red_center = tuple(projected[0][0])

    return real_world_red_center


def map_path_to_aruco_plane_coords(refined_path, H):
    if H is None:
        print("âŒ H çŸ©é˜µä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåæ ‡æ˜ å°„")
        return []

    try:
        # æ„é€ è·¯å¾„ç‚¹æ•°ç»„ï¼Œæ³¨æ„å›¾åƒåæ ‡æ˜¯ (y, x)ï¼Œéœ€è¦å˜ä¸º (x, y)
        path_array = np.array([[[p[1], p[0]]] for p in refined_path], dtype=np.float32)

        # é€è§†å˜æ¢
        projected = cv2.perspectiveTransform(path_array, H)

        # æå–ç»“æœ
        mapped_path = [tuple(pt[0]) for pt in projected]  # [(x1, y1), (x2, y2), ...]
        return mapped_path

    except Exception as e:
        print(f"âŒ è·¯å¾„æ˜ å°„å¤±è´¥: {e}")
        return []
def inverse_homography_point(pt, H):
    """
    å°†ç‰©ç†åæ ‡ç³»ä¸­çš„ç‚¹ (x, y) é€šè¿‡ Hâ»Â¹ æ˜ å°„å›å›¾åƒåæ ‡ç³» (u, v)
    """
    inv_H = np.linalg.inv(H)
    pt_arr = np.array([[[pt[0], pt[1]]]], dtype=np.float32)  # æ³¨æ„æ˜¯ [[(x, y)]]
    img_pt = cv2.perspectiveTransform(pt_arr, inv_H)
    return int(img_pt[0][0][0]), int(img_pt[0][0][1])


class RedBallTrackerGUI:
    def __init__(self, window, window_title):
        self.window = window
        self.window.title(window_title)
        self.frame_count = 0

        # åˆ›å»ºä¸»frameä¸ºæ¨ªå‘å¸ƒå±€
        self.main_frame = tk.Frame(window)
        self.main_frame.pack(fill=tk.BOTH, expand=True)

        # å·¦ä¾§æŒ‰é’®åŒº
        self.left_frame = tk.Frame(self.main_frame)
        self.left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=10, pady=10)

        self.start_button = Button(self.left_frame, text="Start", width=15, command=self.start_system)
        self.start_button.pack(pady=5)

        self.stop_button = Button(self.left_frame, text="Stop", width=15, command=self.stop_system, state=tk.DISABLED)
        self.stop_button.pack(pady=5)

        self.save_button = Button(self.left_frame, text="Save CSV", width=15, command=self.save_errors)
        self.save_button.pack(pady=5)

        self.regen_button = Button(self.left_frame, text="Regenerate Path", width=15, command=self.regenerate_path)
        self.regen_button.pack(pady=5)

        self.reset_button = Button(self.left_frame, text="Reset Errors", width=15, command=self.reset_errors)
        self.reset_button.pack(pady=5)

        self.status_label = Label(self.left_frame, text="Status: Idle", fg="blue")
        self.status_label.pack(pady=10)

        self.coord_label = Label(self.left_frame, text="Coord: (x, y)")
        self.coord_label.pack(pady=5)

        # å³ä¾§è§†é¢‘ + å›¾å½¢åŒº
        self.right_frame = tk.Frame(self.main_frame)
        self.right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=10, pady=10)

        self.video_label = Label(self.right_frame)
        self.video_label.pack()

        self.error_label = Label(self.right_frame, text="", font=("Arial", 12))
        self.error_label.pack(pady=10)

        self.fig, self.ax = plt.subplots(figsize=(5, 2))
        self.ax.set_title("Tracking Error (cm)")
        self.ax.set_xlabel("Frames")
        self.ax.set_ylabel("Error")
        self.line, = self.ax.plot([], [], lw=2)
        self.canvas = FigureCanvasTkAgg(self.fig, master=self.right_frame)
        self.canvas.draw()
        self.canvas.get_tk_widget().pack(pady=10)

        self.running = False
        self.pipeline = None
        self.video_capture = None
        self.H = None
        self.refined_path = []
        self.real_world_path = []
        self.path_overlay = None
        self.history_points = deque(maxlen=300)
        self.nearest_points = []
        self.errors = []
        self.timestamps = []

        self.window.mainloop()

    def start_system(self):
        self.running = True
        self.start_button.config(state=tk.DISABLED)
        self.stop_button.config(state=tk.NORMAL)
        self.status_label.config(text="Status: Running", fg="green")

        self.pipeline = (
            "v4l2src device=/dev/video0 ! "
            "image/jpeg,width=1280,height=720,framerate=60/1 ! "
            "jpegdec ! videoconvert ! appsink"
        )
        self.video_capture = cv2.VideoCapture(self.pipeline, cv2.CAP_GSTREAMER)

        if not self.video_capture.isOpened():
            print("é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            self.status_label.config(text="Status: Camera error", fg="red")
            self.running = False
            return

        ret, initial_frame = self.video_capture.read()
        if not ret:
            print("é”™è¯¯ï¼šæ— æ³•è·å–åˆå§‹å›¾åƒ")
            self.status_label.config(text="Status: Frame error", fg="red")
            self.running = False
            return

        self.generate_path(initial_frame)
        self.update()

    def generate_path(self, frame):
        self.path_overlay, red_center, self.refined_path = generate_path_overlay(frame)
        get_aruco_centers(aruco_corners_dict)
        self.H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
        if self.H is not None:
            print("âœ… Homography çŸ©é˜µè®¡ç®—å®Œæˆ")
            self.real_world_path = map_path_to_aruco_plane_coords(self.refined_path, self.H)
            with open('real_world_path.csv', 'w', newline='') as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(['X (cm)', 'Y (cm)'])
                for x, y in self.real_world_path:
                    writer.writerow([x, y])
            print("âœ… å·²ä¿å­˜è·¯å¾„åˆ° real_world_path.csv")

    def regenerate_path(self):
        if self.video_capture:
            ret, frame = self.video_capture.read()
            if ret:
                self.generate_path(frame)
                print("ğŸ”„ å·²é‡æ–°ç”Ÿæˆè·¯å¾„å›¾å±‚")

    def reset_errors(self):
        self.errors.clear()
        self.timestamps.clear()
        self.history_points.clear()
        self.nearest_points.clear()
        self.update_plot()
        print("ğŸ” å·²é‡ç½®è¯¯å·®æ•°æ®")

    def stop_system(self):
        self.running = False
        if self.video_capture:
            self.video_capture.release()
        self.status_label.config(text="Status: Stopped", fg="gray")
        self.window.quit()

    def update(self):
        if not self.running:
            return

        ret, frame = self.video_capture.read()
        if not ret:
            self.stop_system()
            return

        red_center = detect_red_ball(frame)
        display = cv2.addWeighted(self.path_overlay, 0.6, frame, 0.4, 0)

        real_world_red = None
        if red_center:
            real_world_red = detect_aruco_and_map_red_ball(red_center, frame)
            self.coord_label.config(text=f"Coord: ({real_world_red[0]:.1f}, {real_world_red[1]:.1f})")
            self.error_label.config(text=f"Red @ {real_world_red}")

        if real_world_red and self.real_world_path:
            distances = [calculate_distance(real_world_red, pt) for pt in self.real_world_path]
            nearest_idx = int(np.argmin(distances))
            target_idx = nearest_idx + headidx

            if target_idx < len(self.real_world_path):
                target_point = self.real_world_path[target_idx]
                x_c = int(real_world_red[0]*100)
                y_c = int(real_world_red[1]*100)
                x_d = int(target_point[0]*100)
                y_d = int(target_point[1]*100)
                send_two_points_16bit(x_c, y_c, x_d, y_d)
                self.status_label.config(text="Status: Sending", fg="orange")

                target_px = inverse_homography_point(target_point, self.H)
                cv2.circle(display, target_px, 8, (255, 0, 255), -1)
                cv2.putText(display, "Target", (target_px[0] + 10, target_px[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)

                nearest_path_point = self.real_world_path[nearest_idx]
                self.nearest_points.append(nearest_path_point)
                euclidean_error = calculate_distance(real_world_red, nearest_path_point)
                self.errors.append(euclidean_error)
                self.timestamps.append(time.time())
                self.history_points.append(real_world_red)
                self.frame_count += 1
                if self.frame_count % 5 == 0:
                    self.update_plot()


        frame = cv2.cvtColor(display, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(frame)
        imgtk = ImageTk.PhotoImage(image=img)
        self.video_label.imgtk = imgtk
        self.video_label.configure(image=imgtk)

        self.window.after(30, self.update)

    def update_plot(self):
        self.line.set_data(range(len(self.errors)), self.errors)
        self.ax.set_xlim(0, max(30, len(self.errors)))
        self.ax.set_ylim(0, max(20, max(self.errors) + 5 if self.errors else 25))
        self.canvas.draw()

    def save_errors(self):
        with open('tracking_accuracy.csv', 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Timestamp', 'Error (cm)', 'Red_X (cm)', 'Red_Y (cm)', 'Nearest_X (cm)', 'Nearest_Y (cm)'])
            for t, e, red_pt, path_pt in zip(self.timestamps, self.errors, self.history_points, self.nearest_points):
                writer.writerow([
                    f"{t:.3f}", f"{e:.3f}",
                    f"{red_pt[0]:.3f}", f"{red_pt[1]:.3f}",
                    f"{path_pt[0]:.3f}", f"{path_pt[1]:.3f}"
                ])
        print("âœ… å·²ä¿å­˜è¯¯å·®æ•°æ® tracking_accuracy.csv")

# å¯åŠ¨ GUI
if __name__ == "__main__":
    root = tk.Tk()
    app = RedBallTrackerGUI(root, "Red Ball Tracker GUI")
