import cv2
import numpy as np
import math
import smbus
from collections import deque
from scipy.spatial import cKDTree
from scipy.interpolate import splprep, splev
import time  # åŠ åœ¨æœ€é¡¶éƒ¨å’Œå…¶ä»– import æ”¾ä¸€èµ·
import csv

from cv2 import aruco
#Aruco è®¾ç½®
ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_4X4_50)
ARUCO_PARAMS = aruco.DetectorParameters_create()

# I2C è®¾ç½®
bus = smbus.SMBus(1)
arduino_address = 0x08

def int16_to_bytes(val):
    val = int(val)
    if val < 0:
        val = (1 << 16) + val
    return [(val >> 8) & 0xFF, val & 0xFF]
'''
def send_two_points_16bit(x1, y1, x2, y2):
    data = int16_to_bytes(x1) + int16_to_bytes(y1) + int16_to_bytes(x2) + int16_to_bytes(y2)
    try:
        bus.write_i2c_block_data(arduino_address, 0x00, data)
        print(f"Sent: ({x1}, {y1}) -> ({x2}, {y2})")
    except Exception as e:
        print(f"I2C Send Error: {e}")
'''
def send_two_points_16bit(x1, y1, x2, y2):
    global last_send_time
    now = time.time()
    if now - last_send_time < SEND_INTERVAL:
        print(f"time out")
        return  # æ—¶é—´é—´éš”ä¸è¶³ï¼Œä¸å‘é€
    last_send_time = now  # æ›´æ–°æ—¶é—´æˆ³

    data = int16_to_bytes(x1) + int16_to_bytes(y1) + int16_to_bytes(x2) + int16_to_bytes(y2)
    try:
        bus.write_i2c_block_data(arduino_address, 0x00, data)
        print(f"Sent: ({x1}, {y1}) -> ({x2}, {y2})")
    except Exception as e:
        print(f"I2C Send Error: {e}")

# å‚æ•°
INTERPOLATION_COUNT = 2
headidx = 30
lower_red_1 = np.array([0, 100, 50])
upper_red_1 = np.array([10, 255, 255])
lower_red_2 = np.array([170, 100, 50])
upper_red_2 = np.array([180, 255, 255])
lower_black = np.array([0, 0, 0])
upper_black = np.array([180, 255, 50])
last_send_time = 0  # å…¨å±€å˜é‡ï¼Œè®°å½•ä¸Šæ¬¡å‘é€çš„æ—¶é—´æˆ³
SEND_INTERVAL = 0.04  # å‘é€é—´éš” 50 æ¯«ç§’
errors = []  # ç”¨äºä¿å­˜æ¯å¸§çš„è¯¯å·®å€¼
timestamps = []  # ä¿å­˜æ¯å¸§çš„æ—¶é—´æˆ³
history_points = deque(maxlen=300)  # çº¢çƒå†å²åæ ‡ï¼Œç”¨äºç”»è½¨è¿¹
nearest_points = []  # âœ… æ–°å¢è®°å½•æœ€è¿‘è·¯å¾„ç‚¹
aruco_corners_dict = {}  # ç”¨äºå­˜å‚¨å››ä¸ªArUco markerçš„è§’ç‚¹
aruco_roi_list = [] #ArUco ROIåˆå§‹åŒ–
aruco_centers_dict = {}  # ç”¨äºä¿å­˜æ¯ä¸ª ArUco ID çš„ä¸­å¿ƒç‚¹åæ ‡

last_red_center = None  # ğŸ‘ˆ æ”¾åœ¨å…¨å±€å˜é‡åŒºåŸŸ

x__1 = 0
x__2 = 0
y__1 = 0
y__2 = 0

# å®æ—¶è¯†åˆ«çº¢çƒä½ç½®
def detect_red_ball(frame):
    global last_red_center
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # é»˜è®¤ä½¿ç”¨æ•´å¼ å›¾åƒ
    h, w = frame.shape[:2]
    roi_margin = 60

    if last_red_center:
        yc, xc = last_red_center
        y_min = max(0, yc - roi_margin)
        y_max = min(h, yc + roi_margin)
        x_min = max(0, xc - roi_margin)
        x_max = min(w, xc + roi_margin)

        roi_hsv = hsv[y_min:y_max, x_min:x_max]
        red_mask = cv2.bitwise_or(
            cv2.inRange(roi_hsv, lower_red_1, upper_red_1),
            cv2.inRange(roi_hsv, lower_red_2, upper_red_2)
        )
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        max_area = 0
        best_center = None
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area > 100 and area > max_area:
                x, y, w_box, h_box = cv2.boundingRect(cnt)
                best_center = (y + h_box // 2 + y_min, x + w_box // 2 + x_min)  # åŠ åç§»
                max_area = area

        if best_center is not None:
            last_red_center = best_center
            return best_center

    # Fallbackï¼šæ•´å›¾æŸ¥æ‰¾
    red_mask = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red_1, upper_red_1),
        cv2.inRange(hsv, lower_red_2, upper_red_2)
    )
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    max_area = 0
    best_center = None
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 100 and area > max_area:
            x, y, w_box, h_box = cv2.boundingRect(cnt)
            best_center = (y + h_box // 2, x + w_box // 2)
            max_area = area

    if best_center is not None:
        last_red_center = best_center
    return best_center

def calculate_distance(pt1, pt2):
    return math.hypot(pt1[0] - pt2[0], pt1[1] - pt2[1])


# è·¯å¾„å›¾å±‚å‡½æ•°
def generate_path_overlay(image):
    '''
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    
    selected_path_image = np.zeros_like(image)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        perimeter = cv2.arcLength(cnt, True)

        # === æ´å£è¿‡æ»¤é€»è¾‘ ===
        if area > 2000:  # è·³è¿‡å¤ªå¤§çš„åŒºåŸŸï¼Œé¿å…è¯†åˆ«åˆ°æ´
            continue
        if cv2.isContourConvex(cnt):  # è·³è¿‡é—­åˆç¯
            continue

        if 50 < area < 1500 and perimeter > 80:
            approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)
            if len(approx) > 5:
                cv2.drawContours(selected_path_image, [cnt], -1, (255, 255, 255), 2)
    
  
    # éª¨æ¶æå–
    gray_selected = cv2.cvtColor(selected_path_image, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray_selected, 127, 255, cv2.THRESH_BINARY)
    skeleton = cv2.ximgproc.thinning(binary)
    non_zero_points = np.column_stack(np.where(skeleton > 0))
    '''
    global aruco_corners_dict

    # åŸºäºé¢œè‰²çš„é»‘çº¿æ©è†œæå–è·¯å¾„ï¼ˆé¿å…è¯†åˆ«åˆ°æ´ï¼‰    
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    black_mask = cv2.inRange(hsv, lower_black, upper_black)
    black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))

    # éª¨æ¶æå–ï¼ˆé»‘çº¿ç»†åŒ–ï¼‰
    skeleton = cv2.ximgproc.thinning(black_mask)
    non_zero_points = np.column_stack(np.where(skeleton > 0))

    # çº¢çƒæ£€æµ‹
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    red_mask = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red_1, upper_red_1),
        cv2.inRange(hsv, lower_red_2, upper_red_2)
    )
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    red_center = None
    max_area = 0
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 100 and area > max_area:
            x, y, w, h = cv2.boundingRect(cnt)
            red_center = (y + h // 2, x + w // 2)
            max_area = area

    # fallback èµ·ç‚¹ï¼šè‹¥æœªè¯†åˆ«çº¢çƒï¼Œåˆ™ä½¿ç”¨å›¾åƒä¸­å¿ƒæœ€è¿‘çš„éª¨æ¶ç‚¹
    if red_center is None:
        print("âš ï¸ æœªæ£€æµ‹åˆ°çº¢çƒï¼Œè‡ªåŠ¨ä½¿ç”¨è·¯å¾„éª¨æ¶ä¸Šçš„ç‚¹ä½œä¸ºèµ·ç‚¹")
        if len(non_zero_points) == 0:
            return image.copy(), None, []
        center_yx = np.array([image.shape[0] // 2, image.shape[1] // 2])
        distances = np.linalg.norm(non_zero_points - center_yx, axis=1)
        nearest_idx = np.argmin(distances)
        red_center = tuple(non_zero_points[nearest_idx])

    # ç¨€ç–åŒ–éª¨æ¶ç‚¹
    kdtree = cKDTree(non_zero_points)
    placed_points, used_indices = [], set()
    for idx, point in enumerate(non_zero_points):
        if idx not in used_indices:
            placed_points.append(point)
            used_indices.update(kdtree.query_ball_point(point, r=15))
    placed_points = np.array(placed_points)

    # ä»çº¢çƒèµ·ç‚¹å‡ºå‘æ„å»ºæœ‰åºè·¯å¾„
    all_points = placed_points.tolist()
    ordered_path = [red_center]
    used = set()
    current_point = red_center
    kdtree_path = cKDTree(all_points)

    while True:
        distances, indices = kdtree_path.query(current_point, k=len(all_points))
        next_point = None
        for idx in indices:
            candidate = tuple(all_points[idx])
            #if candidate not in used and calculate_distance(current_point, candidate) < 65:
            if candidate not in used and calculate_distance(current_point, candidate) < 100:
                next_point = candidate
                break
        if next_point is None:
            break
        ordered_path.append(next_point)
        used.add(next_point)
        current_point = next_point

    # æ’å€¼ç”Ÿæˆ refined_path
    refined_path = []
    for i in range(len(ordered_path) - 1):
        p1 = np.array(ordered_path[i])
        p2 = np.array(ordered_path[i + 1])
        refined_path.append(tuple(p1))
        for j in range(1, INTERPOLATION_COUNT + 1):
            ratio = j / (INTERPOLATION_COUNT + 1)
            new_point = tuple(((1 - ratio) * p1 + ratio * p2).astype(int))
            refined_path.append(new_point)
    refined_path.append(tuple(ordered_path[-1]))

    # âœ… âœ… âœ… åœ¨è¿™é‡Œæ’å…¥ spline å¹³æ»‘éƒ¨åˆ† âœ… âœ… âœ…
    if len(refined_path) >= 4:
        try:
            path_array = np.array(refined_path)
            y_points, x_points = path_array[:, 0], path_array[:, 1]

            from scipy.interpolate import splprep, splev
            tck, u = splprep([x_points, y_points], s=1000, k=3)
            u_fine = np.linspace(0, 1, len(refined_path) * 5)
            x_smooth, y_smooth = splev(u_fine, tck)
            refined_path = [(int(y), int(x)) for x, y in zip(x_smooth, y_smooth)]
        except Exception as e:
            print(f"âš ï¸ Bæ ·æ¡æ‹Ÿåˆå¤±è´¥ï¼Œä¿ç•™åŸå§‹æ’å€¼è·¯å¾„ã€‚åŸå› : {e}")
    else:
        print("âš ï¸ è·¯å¾„ç‚¹æ•°ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œ Bæ ·æ¡å¹³æ»‘")

    # âœ… ä¿ç•™è·¯å¾„å¯è§†åŒ–
    overlay = image.copy()
    for i in range(len(refined_path) - 1):
        cv2.line(overlay, (refined_path[i][1], refined_path[i][0]),
                      (refined_path[i + 1][1], refined_path[i + 1][0]), (0, 255, 255), 1)

    # === [ArUco æ£€æµ‹é€»è¾‘ï¼Œå¹¶ä¸”è®¾ç½®å››ä¸ªROI]  ===
    aruco_roi_list.clear()#æ¸…ç†å¯èƒ½æ®‹ç•™çš„ROIä¿¡æ¯
    margin = 80 #è®¾ç½®æ§åˆ¶ç”¨äºæ£€æµ‹ArUcoçš„ROIå¤§å°çš„å˜é‡
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)
    if ids is None:
        print("è·¯çº¿æ£€æµ‹æ—¶æ²¡æœ‰æ£€æµ‹åˆ° ä»»ä½•ArUco")
        return []
    else:
        for i, marker_id in enumerate(ids.flatten()):
            if 0 <= marker_id <= 3:
                pts = corners[i][0]  # shape: (4, 2)
                aruco_corners_dict[marker_id] = pts
                x_min = max(0, int(np.min(pts[:, 0])) - margin)
                x_max = min(image.shape[1], int(np.max(pts[:, 0])) + margin)
                y_min = max(0, int(np.min(pts[:, 1])) - margin)
                y_max = min(image.shape[0], int(np.max(pts[:, 1])) + margin)
                aruco_roi_list.append((marker_id, (x_min, x_max, y_min, y_max)))

    if len(aruco_roi_list) < 4:
        print("âš ï¸ æ£€æµ‹åˆ°çš„ ArUco ä¸å®Œæ•´ï¼Œå¯èƒ½ä¸åŒ…å«å…¨éƒ¨ 0~3")
    else:
        print("âœ… åˆå§‹ ArUco ROI åŒºåŸŸæå–å®Œæˆ") 

    if ids is not None:
        aruco.drawDetectedMarkers(overlay, corners, ids)
        for i, marker_id in enumerate(ids.flatten()):
            pts = corners[i][0]
            cx = int(np.mean(pts[:, 0]))
            cy = int(np.mean(pts[:, 1]))
            cv2.circle(overlay, (cx, cy), 4, (0, 255, 0), -1)
            cv2.putText(overlay, f"ID: {marker_id}", (cx + 10, cy - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return overlay, red_center, refined_path
#å°†å››ä¸ªè§’åæ ‡è½¬æ¢ä¸ºä¸­å¿ƒåæ ‡
def get_aruco_centers(aruco_corners_dict):
    global aruco_centers_dict
    aruco_centers_dict.clear()
    for marker_id, corners in aruco_corners_dict.items():
        center = np.mean(corners, axis=0)
        aruco_centers_dict[marker_id] = tuple(center)

#ç”Ÿæˆ H çŸ©é˜µ åŠ å…¥ä¸­å¿ƒç‚¹è½¬åŒ–
def compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17)):
    if len(aruco_centers_dict) < 4:
        print("âš ï¸ ArUco ä¸­å¿ƒç‚¹ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆ H çŸ©é˜µ")
        return None

    # 1. æå–å››ä¸ª marker ä¸­å¿ƒç‚¹ï¼ˆæŒ‰ç…§ä½ æŒ‡å®šçš„é¡ºåºï¼‰
    try:
        src_pts = np.array([
            aruco_centers_dict[0],
            aruco_centers_dict[1],
            aruco_centers_dict[2],
            aruco_centers_dict[3]
        ], dtype=np.float32)
    except KeyError as e:
        print(f"âš ï¸ ç¼ºå¤± ArUco {e}ï¼Œè¯·ç¡®è®¤0~3å…¨éƒ¨è¯†åˆ«åˆ°äº†")
        return None

    # 2. å®šä¹‰ç›®æ ‡åæ ‡ç‚¹ï¼ˆä½ å¸Œæœ›ä»–ä»¬å¯¹åº”çš„ä½ç½®ï¼Œæ¯”å¦‚ä¸€ä¸ª 400x400 çš„æ£‹ç›˜ï¼‰
    dst_pts = np.array([
        [-(target_size[0]/2), (target_size[1]/2)],             # ArUco 0 â†’ å·¦ä¸Šè§’
        [(target_size[0]/2), (target_size[1]/2)],       # ArUco 1 â†’ å³ä¸Šè§’
        [(target_size[0]/2), -(target_size[1]/2)], # ArUco 2 â†’ å³ä¸‹è§’
        [-(target_size[0]/2), -(target_size[1]/2)]        # ArUco 3 â†’ å·¦ä¸‹è§’
    ], dtype=np.float32)

    # 3. è®¡ç®— Homography
    H = cv2.getPerspectiveTransform(src_pts, dst_pts)
    return H
#å®æ—¶æ£€æµ‹ARUCOçš„ä½ç½®ï¼ˆå››ä¸ª ROI ä¸­çš„ ï¼‰
def detect_aruco_and_update(frame):
    global aruco_corners_dict, aruco_centers_dict, aruco_roi_list
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # å¦‚æœ ROI åŒºåŸŸå­˜åœ¨ï¼Œå…ˆè¿›è¡Œ ROI è£å‰ªå¹¶åªåœ¨è¯¥åŒºåŸŸæ£€æµ‹
    if aruco_roi_list:
        for roi in aruco_roi_list:
            marker_id, (x_min, x_max, y_min, y_max) = roi
            roi_frame = gray[y_min:y_max, x_min:x_max]
            corners, ids, _ = aruco.detectMarkers(roi_frame, ARUCO_DICT, parameters=ARUCO_PARAMS)

            # æ£€æµ‹åˆ° ArUco marker åæ›´æ–°å­—å…¸
            if ids is not None:
                for i, marker_id in enumerate(ids.flatten()):
                    if 0 <= marker_id <= 3:
                        pts = corners[i][0] + np.array([x_min, y_min])  # æ·»åŠ  ROI åç§»
                        aruco_corners_dict[marker_id] = pts
                        center = np.mean(pts, axis=0)
                        aruco_centers_dict[marker_id] = tuple(center)

        print(f"ğŸ” å®æ—¶æ£€æµ‹åˆ° ArUco ID: {list(aruco_corners_dict.keys())}")
    else:
        # å¦‚æœæ²¡æœ‰ ROIï¼Œç›´æ¥åœ¨æ•´ä¸ªå›¾åƒä¸Šè¿›è¡Œæ£€æµ‹
        corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)

        if ids is not None:
            aruco_corners_dict.clear()
            aruco_centers_dict.clear()
            for i, marker_id in enumerate(ids.flatten()):
                if 0 <= marker_id <= 3:
                    pts = corners[i][0]
                    aruco_corners_dict[marker_id] = pts
                    center = np.mean(pts, axis=0)
                    aruco_centers_dict[marker_id] = tuple(center)
            print(f"ğŸ” å®æ—¶æ£€æµ‹åˆ° ArUco ID: {list(aruco_corners_dict.keys())}")
        else:
            print("âš ï¸ å®æ—¶æœªæ£€æµ‹åˆ°ä»»ä½• ArUco")

#ä½¿ç”¨è¯†åˆ«å‡ºæ¥çš„ArUcoè¿›è¡Œå°çƒåæ ‡è¿˜åŸ            
def detect_aruco_and_map_red_ball(red_center, frame):
    """
    å·²çŸ¥çº¢çƒå›¾åƒåæ ‡ red_centerï¼Œ
    è‡ªåŠ¨æ£€æµ‹ ArUco markerã€è®¡ç®— H çŸ©é˜µï¼Œå¹¶å°† red_center æ˜ å°„åˆ° ArUco å¹³é¢åæ ‡ç³»ä¸­ã€‚
    
    å‚æ•°ï¼š
        red_center: tuple(int, int)ï¼Œå›¾åƒåæ ‡ä¸‹çš„çº¢çƒä½ç½® (y, x)
        frame: å½“å‰å›¾åƒå¸§
    
    è¿”å›ï¼š
        real_world_red_center: tuple(float, float)ï¼Œæ˜ å°„åˆ° ArUco å¹³é¢åæ ‡ç³»çš„åæ ‡ (x, y)
    """
    if red_center is None:
        print("âš ï¸ è¾“å…¥çš„ red_center ä¸ºç©ºï¼Œè·³è¿‡")
        return None

    # 1. å®æ—¶æ£€æµ‹ ArUco marker å¹¶æ›´æ–° ROI å’Œè§’ç‚¹å­—å…¸
    detect_aruco_and_update(frame)

    # 2. è·å–ä¸­å¿ƒç‚¹
    get_aruco_centers(aruco_corners_dict)

    # 3. è®¡ç®— Homography çŸ©é˜µ
    H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
    if H is None:
        print("âŒ æ— æ³•è®¡ç®— Homographyï¼Œè¿”å› None")
        return None

    # 4. å°†çº¢çƒå›¾åƒåæ ‡è½¬æ¢ä¸º ArUco å¹³é¢åæ ‡ç³»
    point_arr = np.array([[[red_center[1], red_center[0]]]], dtype=np.float32)  # æ³¨æ„é¡ºåº x, y
    projected = cv2.perspectiveTransform(point_arr, H)
    real_world_red_center = tuple(projected[0][0])

    return real_world_red_center


def map_path_to_aruco_plane_coords(refined_path, H):
    if H is None:
        print("âŒ H çŸ©é˜µä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåæ ‡æ˜ å°„")
        return []

    try:
        # æ„é€ è·¯å¾„ç‚¹æ•°ç»„ï¼Œæ³¨æ„å›¾åƒåæ ‡æ˜¯ (y, x)ï¼Œéœ€è¦å˜ä¸º (x, y)
        path_array = np.array([[[p[1], p[0]]] for p in refined_path], dtype=np.float32)

        # é€è§†å˜æ¢
        projected = cv2.perspectiveTransform(path_array, H)

        # æå–ç»“æœ
        mapped_path = [tuple(pt[0]) for pt in projected]  # [(x1, y1), (x2, y2), ...]
        return mapped_path

    except Exception as e:
        print(f"âŒ è·¯å¾„æ˜ å°„å¤±è´¥: {e}")
        return []
def inverse_homography_point(pt, H):
    """
    å°†ç‰©ç†åæ ‡ç³»ä¸­çš„ç‚¹ (x, y) é€šè¿‡ Hâ»Â¹ æ˜ å°„å›å›¾åƒåæ ‡ç³» (u, v)
    """
    inv_H = np.linalg.inv(H)
    pt_arr = np.array([[[pt[0], pt[1]]]], dtype=np.float32)  # æ³¨æ„æ˜¯ [[(x, y)]]
    img_pt = cv2.perspectiveTransform(pt_arr, inv_H)
    return int(img_pt[0][0][0]), int(img_pt[0][0][1])


# æ‘„åƒå¤´å¯åŠ¨
pipeline = (
    "v4l2src device=/dev/video0 ! "
    "image/jpeg,width=1280,height=720,framerate=60/1 ! "
    "jpegdec ! videoconvert ! appsink"
)
video_capture = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
if not video_capture.isOpened():
    print("é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
    exit()

ret, initial_frame = video_capture.read()
if not ret:
    print("é”™è¯¯ï¼šæ— æ³•è·å–åˆå§‹å›¾åƒ")
    exit()

path_overlay, red_center, refined_path = generate_path_overlay(initial_frame)
print(f"è·¯å¾„èµ·ç‚¹ï¼š{red_center}ï¼Œè·¯å¾„é•¿åº¦ï¼š{len(refined_path)}")

#å¼€å§‹ä½¿ç”¨Homographyè½¬åŒ–è·¯å¾„
get_aruco_centers(aruco_corners_dict)
H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
if H is not None:
    print("âœ… Homography çŸ©é˜µè®¡ç®—å®Œæˆ")
    print(H)
real_world_path = map_path_to_aruco_plane_coords(refined_path, H)
# å¯¼å‡ºè·¯å¾„åæ ‡ç‚¹ï¼ˆå•ä½æ˜¯ä»¥ ArUco å¹³é¢ä¸­å¿ƒä¸º (0, 0) çš„å®é™…åæ ‡ç³»ï¼‰
with open('real_world_path.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['X (cm)', 'Y (cm)'])  # æˆ–è€…å•ä½æ˜¯ä½ è®¾ç½®çš„æ ¼å­å•ä½
    for x, y in real_world_path:
        writer.writerow([x, y])
print("âœ… å·²ä¿å­˜è·¯å¾„åˆ° real_world_path.csv")

'''
#å¾—åˆ° H åï¼Œåœ¨ refined_path ä¸ŠåšæŠ•å½±
if H is not None:
    path_array = np.array(refined_path, dtype=np.float32)
    path_array = np.array([[[p[1], p[0]]] for p in refined_path], dtype=np.float32)  # æ³¨æ„é¡ºåºï¼šx, y
    projected_path = cv2.perspectiveTransform(path_array, H)
    real_world_path = [(float(p[0][0]), float(p[0][1])) for p in projected_path]  # æ£‹ç›˜å•ä½ä¸‹çš„è·¯å¾„ç‚¹
'''
real_world_red = None
while True:
    ret, frame = video_capture.read()
    if not ret:
        break

    red_center = detect_red_ball(frame)
    display = cv2.addWeighted(path_overlay, 0.6, frame, 0.4, 0)

    if red_center:
        real_world_red = detect_aruco_and_map_red_ball(red_center, frame)
    #if real_world_red:
     #   print(f"çº¢çƒåœ¨ ArUco å¹³é¢åæ ‡ç³»ä¸­çš„ä½ç½®: {real_world_red}")

    if real_world_red and real_world_path:
        # === åœ¨ç‰©ç†åæ ‡ç³»ä¸­è®¡ç®—è·ç¦» ===
        distances = [calculate_distance(real_world_red, pt) for pt in real_world_path]
        nearest_idx = int(np.argmin(distances))
        target_idx = nearest_idx + headidx

        if target_idx < len(real_world_path):
            target_point = real_world_path[target_idx]
            print(f"[Current] çº¢çƒ: X={real_world_red[0]:.2f}, Y={real_world_red[1]:.2f}")
            print(f"[Target ] ç›®æ ‡: X={target_point[0]:.2f}, Y={target_point[1]:.2f}")

            # === æ˜ å°„ç›®æ ‡ç‚¹åˆ°å›¾åƒåæ ‡ç”¨äºå¯è§†åŒ– ===
            target_px = inverse_homography_point(target_point, H)

            # åœ¨å›¾åƒä¸­ç”»ç›®æ ‡ç‚¹
            cv2.circle(display, target_px, 8, (255, 0, 255), -1)
            cv2.putText(display, "Target", (target_px[0] + 10, target_px[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)

            # === è¯¯å·®ç»Ÿè®¡ï¼ˆä»ç„¶ä½¿ç”¨ç‰©ç†åæ ‡è·ç¦»ï¼‰ ===
            nearest_path_point = real_world_path[nearest_idx]
            nearest_points.append(nearest_path_point)

            euclidean_error = calculate_distance(real_world_red, nearest_path_point)
            errors.append(euclidean_error)
            timestamps.append(time.time())
            history_points.append(real_world_red)

            if len(errors) % 30 == 0:
                print(f"[è¯¯å·®ç»Ÿè®¡] å¹³å‡: {np.mean(errors):.2f} cm, æœ€å¤§: {np.max(errors):.2f} cm, æ ‡å‡†å·®: {np.std(errors):.2f} cm")

            # === æ§åˆ¶è¾“å‡ºåæ ‡ï¼ˆå¦‚æœéœ€è¦å‘é€ï¼‰ ===
            x__1 = real_world_red[0]
            y__1 = real_world_red[1]
            x__2 = target_point[0]
            y__2 = target_point[1]

                
    cv2.imshow("Red Ball Tracking", display)

    if errors:
        current_error = errors[-1]
        cv2.putText(display, f"Error: {int(current_error)} px", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break
    elif key == ord('p'):
        ret, new_frame = video_capture.read()
        if ret:
            path_overlay, red_center, refined_path = generate_path_overlay(new_frame)
            real_world_path = map_path_to_aruco_plane_coords(refined_path, H)
            print("[çƒ­é”®P] é‡æ–°ç”Ÿæˆè·¯å¾„å›¾å±‚")
    elif key == ord('s'):
        with open('tracking_accuracy.csv', 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Timestamp', 'Error (cm)', 
                         'Red_X (cm)', 'Red_Y (cm)', 
                         'Nearest_X (cm)', 'Nearest_Y (cm)'])
            for t, e, red_pt, path_pt in zip(timestamps, errors, history_points, nearest_points):
                writer.writerow([
                f"{t:.3f}",
                f"{e:.3f}",
                f"{red_pt[0]:.3f}", f"{red_pt[1]:.3f}",
                f"{path_pt[0]:.3f}", f"{path_pt[1]:.3f}"
                ])
        print("âœ… [çƒ­é”®S] å·²ä¿å­˜ç‰©ç†ç©ºé—´è¯¯å·®æ•°æ®åˆ° tracking_accuracy.csv")



video_capture.release()
cv2.destroyAllWindows()
