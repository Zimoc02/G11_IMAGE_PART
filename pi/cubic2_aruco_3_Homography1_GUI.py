import tkinter as tk
from tkinter import ttk
from PIL import Image, ImageTk
import threading
import cv2
import numpy as np
import math
import smbus
from collections import deque
from scipy.spatial import cKDTree
from scipy.interpolate import splprep, splev
import time
import csv
import os
import sys
import signal
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from cv2 import aruco
from tkinter import messagebox

# ========== åŸå§‹å‚æ•°å’Œè®¾ç½®ä¿æŒä¸å˜ ==========
ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_4X4_50)
ARUCO_PARAMS = aruco.DetectorParameters_create()
bus = smbus.SMBus(1)
arduino_address = 0x08

INTERPOLATION_COUNT = 2
headidx = 30
lower_red_1 = np.array([0, 120, 20])
upper_red_1 = np.array([10, 255, 120])
lower_red_2 = np.array([170, 120, 20])
upper_red_2 = np.array([180, 255, 120])
lower_black = np.array([0, 0, 0])
upper_black = np.array([180, 255, 50])
last_send_time = 0
SEND_INTERVAL = 0.04

errors = []
timestamps = []
history_points = deque(maxlen=300)
nearest_points = []
aruco_corners_dict = {}
aruco_roi_list = []
aruco_centers_dict = {}

real_world_path = []
path_overlay = None
H = None

video_running = False
video_thread = None
video_capture = None
canvas = None
photo = None
panel = None

red_center = None
target_point = None
real_world_red = None

start_time = None  # ç¨‹åºè¿è¡Œèµ·å§‹æ—¶é—´ï¼ˆæ–°å¢ï¼‰


def int16_to_bytes(val):
    val = int(val)
    if val < 0:
        val = (1 << 16) + val
    return [(val >> 8) & 0xFF, val & 0xFF]


def send_two_points_16bit(x1, y1, x2, y2):
    global last_send_time
    now = time.time()
    if now - last_send_time < SEND_INTERVAL:
        return
    last_send_time = now
    data = int16_to_bytes(x1) + int16_to_bytes(y1) + int16_to_bytes(x2) + int16_to_bytes(y2)
    try:
        bus.write_i2c_block_data(arduino_address, 0x00, data)
    except:
        pass


# ========== åŸå§‹å›¾åƒå¤„ç†é€»è¾‘ä¸­çš„å‡½æ•°ä¿æŒä¸å˜ ==========
# ...
# ä¸ºèŠ‚çœç¯‡å¹…ï¼Œç•¥å» `generate_path_overlay`, `detect_red_ball`, `compute_homography_from_aruco`, ç­‰å‡½æ•°
# è¯·å°†è¿™äº›å‡½æ•°åŸå°ä¸åŠ¨åœ°å¤åˆ¶ç²˜è´´è¿›æ¥
x__1 = 0
x__2 = 0
y__1 = 0
y__2 = 0

# å®æ—¶è¯†åˆ«çº¢çƒä½ç½®
def detect_red_ball(frame):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    red_mask = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red_1, upper_red_1),
        cv2.inRange(hsv, lower_red_2, upper_red_2)
    )
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    red_center = None
    max_area = 0
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 100 and area > max_area:
            x, y, w, h = cv2.boundingRect(cnt)
            red_center = (y + h // 2, x + w // 2)
            max_area = area
    return red_center

def calculate_distance(pt1, pt2):
    return math.hypot(pt1[0] - pt2[0], pt1[1] - pt2[1])


# è·¯å¾„å›¾å±‚å‡½æ•°
def generate_path_overlay(image):
    '''
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    
    selected_path_image = np.zeros_like(image)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        perimeter = cv2.arcLength(cnt, True)

        # === æ´å£è¿‡æ»¤é€»è¾‘ ===
        if area > 2000:  # è·³è¿‡å¤ªå¤§çš„åŒºåŸŸï¼Œé¿å…è¯†åˆ«åˆ°æ´
            continue
        if cv2.isContourConvex(cnt):  # è·³è¿‡é—­åˆç¯
            continue

        if 50 < area < 1500 and perimeter > 80:
            approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)
            if len(approx) > 5:
                cv2.drawContours(selected_path_image, [cnt], -1, (255, 255, 255), 2)
    
  
    # éª¨æ¶æå–
    gray_selected = cv2.cvtColor(selected_path_image, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray_selected, 127, 255, cv2.THRESH_BINARY)
    skeleton = cv2.ximgproc.thinning(binary)
    non_zero_points = np.column_stack(np.where(skeleton > 0))
    '''
    global aruco_corners_dict

    # åŸºäºé¢œè‰²çš„é»‘çº¿æ©è†œæå–è·¯å¾„ï¼ˆé¿å…è¯†åˆ«åˆ°æ´ï¼‰    
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    black_mask = cv2.inRange(hsv, lower_black, upper_black)
    black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))

    # éª¨æ¶æå–ï¼ˆé»‘çº¿ç»†åŒ–ï¼‰
    skeleton = cv2.ximgproc.thinning(black_mask)
    non_zero_points = np.column_stack(np.where(skeleton > 0))

    # çº¢çƒæ£€æµ‹
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    red_mask = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red_1, upper_red_1),
        cv2.inRange(hsv, lower_red_2, upper_red_2)
    )
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    red_center = None
    max_area = 0
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 100 and area > max_area:
            x, y, w, h = cv2.boundingRect(cnt)
            red_center = (y + h // 2, x + w // 2)
            max_area = area

    # fallback èµ·ç‚¹ï¼šè‹¥æœªè¯†åˆ«çº¢çƒï¼Œåˆ™ä½¿ç”¨å›¾åƒä¸­å¿ƒæœ€è¿‘çš„éª¨æ¶ç‚¹
    if red_center is None:
        print("âš ï¸ æœªæ£€æµ‹åˆ°çº¢çƒï¼Œè‡ªåŠ¨ä½¿ç”¨è·¯å¾„éª¨æ¶ä¸Šçš„ç‚¹ä½œä¸ºèµ·ç‚¹")
        if len(non_zero_points) == 0:
            return image.copy(), None, []
        center_yx = np.array([image.shape[0] // 2, image.shape[1] // 2])
        distances = np.linalg.norm(non_zero_points - center_yx, axis=1)
        nearest_idx = np.argmin(distances)
        red_center = tuple(non_zero_points[nearest_idx])

    # ç¨€ç–åŒ–éª¨æ¶ç‚¹
    kdtree = cKDTree(non_zero_points)
    placed_points, used_indices = [], set()
    for idx, point in enumerate(non_zero_points):
        if idx not in used_indices:
            placed_points.append(point)
            used_indices.update(kdtree.query_ball_point(point, r=10))
    placed_points = np.array(placed_points)

    # ä»çº¢çƒèµ·ç‚¹å‡ºå‘æ„å»ºæœ‰åºè·¯å¾„
    all_points = placed_points.tolist()
    ordered_path = [red_center]
    used = set()
    current_point = red_center
    kdtree_path = cKDTree(all_points)

    while True:
        distances, indices = kdtree_path.query(current_point, k=len(all_points))
        next_point = None
        for idx in indices:
            candidate = tuple(all_points[idx])
            #if candidate not in used and calculate_distance(current_point, candidate) < 65:
            if candidate not in used and calculate_distance(current_point, candidate) < 120:
                next_point = candidate
                break
        if next_point is None:
            break
        ordered_path.append(next_point)
        used.add(next_point)
        current_point = next_point

    # æ’å€¼ç”Ÿæˆ refined_path
    refined_path = []
    for i in range(len(ordered_path) - 1):
        p1 = np.array(ordered_path[i])
        p2 = np.array(ordered_path[i + 1])
        refined_path.append(tuple(p1))
        for j in range(1, INTERPOLATION_COUNT + 1):
            ratio = j / (INTERPOLATION_COUNT + 1)
            new_point = tuple(((1 - ratio) * p1 + ratio * p2).astype(int))
            refined_path.append(new_point)
    refined_path.append(tuple(ordered_path[-1]))

    # âœ… âœ… âœ… åœ¨è¿™é‡Œæ’å…¥ spline å¹³æ»‘éƒ¨åˆ† âœ… âœ… âœ…
    if len(refined_path) >= 4:
        try:
            path_array = np.array(refined_path)
            y_points, x_points = path_array[:, 0], path_array[:, 1]

            from scipy.interpolate import splprep, splev
            tck, u = splprep([x_points, y_points], s=1000, k=3)
            u_fine = np.linspace(0, 1, len(refined_path) * 5)
            x_smooth, y_smooth = splev(u_fine, tck)
            refined_path = [(int(y), int(x)) for x, y in zip(x_smooth, y_smooth)]
        except Exception as e:
            print(f"âš ï¸ Bæ ·æ¡æ‹Ÿåˆå¤±è´¥ï¼Œä¿ç•™åŸå§‹æ’å€¼è·¯å¾„ã€‚åŸå› : {e}")
    else:
        print("âš ï¸ è·¯å¾„ç‚¹æ•°ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œ Bæ ·æ¡å¹³æ»‘")

    # âœ… ä¿ç•™è·¯å¾„å¯è§†åŒ–
    overlay = image.copy()
    for i in range(len(refined_path) - 1):
        cv2.line(overlay, (refined_path[i][1], refined_path[i][0]),
                      (refined_path[i + 1][1], refined_path[i + 1][0]), (0, 255, 255), 1)

    # === [ArUco æ£€æµ‹é€»è¾‘ï¼Œå¹¶ä¸”è®¾ç½®å››ä¸ªROI]  ===
    aruco_roi_list.clear()#æ¸…ç†å¯èƒ½æ®‹ç•™çš„ROIä¿¡æ¯
    margin = 80 #è®¾ç½®æ§åˆ¶ç”¨äºæ£€æµ‹ArUcoçš„ROIå¤§å°çš„å˜é‡
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)
    if ids is None:
        print("è·¯çº¿æ£€æµ‹æ—¶æ²¡æœ‰æ£€æµ‹åˆ° ä»»ä½•ArUco")
        return []
    else:
        for i, marker_id in enumerate(ids.flatten()):
            if 0 <= marker_id <= 3:
                pts = corners[i][0]  # shape: (4, 2)
                aruco_corners_dict[marker_id] = pts
                x_min = max(0, int(np.min(pts[:, 0])) - margin)
                x_max = min(image.shape[1], int(np.max(pts[:, 0])) + margin)
                y_min = max(0, int(np.min(pts[:, 1])) - margin)
                y_max = min(image.shape[0], int(np.max(pts[:, 1])) + margin)
                aruco_roi_list.append((marker_id, (x_min, x_max, y_min, y_max)))

    if len(aruco_roi_list) < 4:
        print("âš ï¸ æ£€æµ‹åˆ°çš„ ArUco ä¸å®Œæ•´ï¼Œå¯èƒ½ä¸åŒ…å«å…¨éƒ¨ 0~3")
    else:
        print("âœ… åˆå§‹ ArUco ROI åŒºåŸŸæå–å®Œæˆ") 

    if ids is not None:
        aruco.drawDetectedMarkers(overlay, corners, ids)
        for i, marker_id in enumerate(ids.flatten()):
            pts = corners[i][0]
            cx = int(np.mean(pts[:, 0]))
            cy = int(np.mean(pts[:, 1]))
            cv2.circle(overlay, (cx, cy), 4, (0, 255, 0), -1)
            cv2.putText(overlay, f"ID: {marker_id}", (cx + 10, cy - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return overlay, red_center, refined_path
#å°†å››ä¸ªè§’åæ ‡è½¬æ¢ä¸ºä¸­å¿ƒåæ ‡
def get_aruco_centers(aruco_corners_dict):
    global aruco_centers_dict
    aruco_centers_dict.clear()
    for marker_id, corners in aruco_corners_dict.items():
        center = np.mean(corners, axis=0)
        aruco_centers_dict[marker_id] = tuple(center)

#ç”Ÿæˆ H çŸ©é˜µ åŠ å…¥ä¸­å¿ƒç‚¹è½¬åŒ–
def compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17)):
    if len(aruco_centers_dict) < 4:
        print("âš ï¸ ArUco ä¸­å¿ƒç‚¹ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆ H çŸ©é˜µ")
        return None

    # 1. æå–å››ä¸ª marker ä¸­å¿ƒç‚¹ï¼ˆæŒ‰ç…§ä½ æŒ‡å®šçš„é¡ºåºï¼‰
    try:
        src_pts = np.array([
            aruco_centers_dict[0],
            aruco_centers_dict[1],
            aruco_centers_dict[2],
            aruco_centers_dict[3]
        ], dtype=np.float32)
    except KeyError as e:
        print(f"âš ï¸ ç¼ºå¤± ArUco {e}ï¼Œè¯·ç¡®è®¤0~3å…¨éƒ¨è¯†åˆ«åˆ°äº†")
        return None

    # 2. å®šä¹‰ç›®æ ‡åæ ‡ç‚¹ï¼ˆä½ å¸Œæœ›ä»–ä»¬å¯¹åº”çš„ä½ç½®ï¼Œæ¯”å¦‚ä¸€ä¸ª 400x400 çš„æ£‹ç›˜ï¼‰
    dst_pts = np.array([
        [-(target_size[0]/2), (target_size[1]/2)],             # ArUco 0 â†’ å·¦ä¸Šè§’
        [(target_size[0]/2), (target_size[1]/2)],       # ArUco 1 â†’ å³ä¸Šè§’
        [(target_size[0]/2), -(target_size[1]/2)], # ArUco 2 â†’ å³ä¸‹è§’
        [-(target_size[0]/2), -(target_size[1]/2)]        # ArUco 3 â†’ å·¦ä¸‹è§’
    ], dtype=np.float32)

    # 3. è®¡ç®— Homography
    H = cv2.getPerspectiveTransform(src_pts, dst_pts)
    return H
#å®æ—¶æ£€æµ‹ARUCOçš„ä½ç½®ï¼ˆå››ä¸ª ROI ä¸­çš„ ï¼‰
def detect_aruco_and_update(frame):
    global aruco_corners_dict, aruco_centers_dict, aruco_roi_list
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # å¦‚æœ ROI åŒºåŸŸå­˜åœ¨ï¼Œå…ˆè¿›è¡Œ ROI è£å‰ªå¹¶åªåœ¨è¯¥åŒºåŸŸæ£€æµ‹
    if aruco_roi_list:
        for roi in aruco_roi_list:
            marker_id, (x_min, x_max, y_min, y_max) = roi
            roi_frame = gray[y_min:y_max, x_min:x_max]
            corners, ids, _ = aruco.detectMarkers(roi_frame, ARUCO_DICT, parameters=ARUCO_PARAMS)

            # æ£€æµ‹åˆ° ArUco marker åæ›´æ–°å­—å…¸
            if ids is not None:
                for i, marker_id in enumerate(ids.flatten()):
                    if 0 <= marker_id <= 3:
                        pts = corners[i][0] + np.array([x_min, y_min])  # æ·»åŠ  ROI åç§»
                        aruco_corners_dict[marker_id] = pts
                        center = np.mean(pts, axis=0)
                        aruco_centers_dict[marker_id] = tuple(center)

        print(f"ğŸ” å®æ—¶æ£€æµ‹åˆ° ArUco ID: {list(aruco_corners_dict.keys())}")
    else:
        # å¦‚æœæ²¡æœ‰ ROIï¼Œç›´æ¥åœ¨æ•´ä¸ªå›¾åƒä¸Šè¿›è¡Œæ£€æµ‹
        corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)

        if ids is not None:
            aruco_corners_dict.clear()
            aruco_centers_dict.clear()
            for i, marker_id in enumerate(ids.flatten()):
                if 0 <= marker_id <= 3:
                    pts = corners[i][0]
                    aruco_corners_dict[marker_id] = pts
                    center = np.mean(pts, axis=0)
                    aruco_centers_dict[marker_id] = tuple(center)
            print(f"ğŸ” å®æ—¶æ£€æµ‹åˆ° ArUco ID: {list(aruco_corners_dict.keys())}")
        else:
            print("âš ï¸ å®æ—¶æœªæ£€æµ‹åˆ°ä»»ä½• ArUco")

#ä½¿ç”¨è¯†åˆ«å‡ºæ¥çš„ArUcoè¿›è¡Œå°çƒåæ ‡è¿˜åŸ            
def detect_aruco_and_map_red_ball(red_center, frame):
    """
    å·²çŸ¥çº¢çƒå›¾åƒåæ ‡ red_centerï¼Œ
    è‡ªåŠ¨æ£€æµ‹ ArUco markerã€è®¡ç®— H çŸ©é˜µï¼Œå¹¶å°† red_center æ˜ å°„åˆ° ArUco å¹³é¢åæ ‡ç³»ä¸­ã€‚
    
    å‚æ•°ï¼š
        red_center: tuple(int, int)ï¼Œå›¾åƒåæ ‡ä¸‹çš„çº¢çƒä½ç½® (y, x)
        frame: å½“å‰å›¾åƒå¸§
    
    è¿”å›ï¼š
        real_world_red_center: tuple(float, float)ï¼Œæ˜ å°„åˆ° ArUco å¹³é¢åæ ‡ç³»çš„åæ ‡ (x, y)
    """
    if red_center is None:
        print("âš ï¸ è¾“å…¥çš„ red_center ä¸ºç©ºï¼Œè·³è¿‡")
        return None

    # 1. å®æ—¶æ£€æµ‹ ArUco marker å¹¶æ›´æ–° ROI å’Œè§’ç‚¹å­—å…¸
    detect_aruco_and_update(frame)

    # 2. è·å–ä¸­å¿ƒç‚¹
    get_aruco_centers(aruco_corners_dict)

    # 3. è®¡ç®— Homography çŸ©é˜µ
    H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
    if H is None:
        print("âŒ æ— æ³•è®¡ç®— Homographyï¼Œè¿”å› None")
        return None

    # 4. å°†çº¢çƒå›¾åƒåæ ‡è½¬æ¢ä¸º ArUco å¹³é¢åæ ‡ç³»
    point_arr = np.array([[[red_center[1], red_center[0]]]], dtype=np.float32)  # æ³¨æ„é¡ºåº x, y
    projected = cv2.perspectiveTransform(point_arr, H)
    real_world_red_center = tuple(projected[0][0])

    return real_world_red_center


def map_path_to_aruco_plane_coords(refined_path, H):
    if H is None:
        print("âŒ H çŸ©é˜µä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåæ ‡æ˜ å°„")
        return []

    try:
        # æ„é€ è·¯å¾„ç‚¹æ•°ç»„ï¼Œæ³¨æ„å›¾åƒåæ ‡æ˜¯ (y, x)ï¼Œéœ€è¦å˜ä¸º (x, y)
        path_array = np.array([[[p[1], p[0]]] for p in refined_path], dtype=np.float32)

        # é€è§†å˜æ¢
        projected = cv2.perspectiveTransform(path_array, H)

        # æå–ç»“æœ
        mapped_path = [tuple(pt[0]) for pt in projected]  # [(x1, y1), (x2, y2), ...]
        return mapped_path

    except Exception as e:
        print(f"âŒ è·¯å¾„æ˜ å°„å¤±è´¥: {e}")
        return []
def inverse_homography_point(pt, H):
    """
    å°†ç‰©ç†åæ ‡ç³»ä¸­çš„ç‚¹ (x, y) é€šè¿‡ Hâ»Â¹ æ˜ å°„å›å›¾åƒåæ ‡ç³» (u, v)
    """
    inv_H = np.linalg.inv(H)
    pt_arr = np.array([[[pt[0], pt[1]]]], dtype=np.float32)  # æ³¨æ„æ˜¯ [[(x, y)]]
    img_pt = cv2.perspectiveTransform(pt_arr, inv_H)
    return int(img_pt[0][0][0]), int(img_pt[0][0][1])



# ========== GUI æ§åˆ¶é€»è¾‘ ===========

def start_video():
    global video_running, video_thread, start_time, video_capture
    video_running = True
    start_time = time.time()
    video_capture = cv2.VideoCapture(0)

    # è·¯å¾„è¯†åˆ«ä¸€æ¬¡
    ret, frame = video_capture.read()
    if ret:
        frame = cv2.flip(frame, 1)  # åŒæ ·åŠ ç¿»è½¬
        overlay, red_center_, refined_path = generate_path_overlay(frame)
        get_aruco_centers(aruco_corners_dict)
        H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
        if refined_path and H is not None:
            real_world_path.clear()
            real_world_path.extend(map_path_to_aruco_plane_coords(refined_path, H))
        else:
            messagebox.showwarning("âš ï¸", "åˆå§‹è·¯å¾„è¯†åˆ«å¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾åƒä¸ArUcoæ ‡ç­¾")
    else:
        messagebox.showwarning("âš ï¸", "æ— æ³•ä»æ‘„åƒå¤´è¯»å–åˆå§‹å›¾åƒ")

    video_thread = threading.Thread(target=video_loop)
    video_thread.start()

def update_runtime():
    if video_running and start_time:
        elapsed = int(time.time() - start_time)
        h = elapsed // 3600
        m = (elapsed % 3600) // 60
        s = elapsed % 60
        runtime_value.config(text=f"{h:02}:{m:02}:{s:02}")
    root.after(1000, update_runtime)

path_display_visible = False
path_canvas = None
path_fig = None
path_ax = None

def toggle_path_display():
    global path_display_visible, path_canvas, path_fig, path_ax
    if not real_world_path:
        messagebox.showwarning("æç¤º", "è·¯å¾„æ•°æ®ä¸ºç©ºï¼")
        return

    if not path_display_visible:
        path_fig = plt.Figure(figsize=(4, 4), dpi=100)
        path_ax = path_fig.add_subplot(111)
        path_canvas = FigureCanvasTkAgg(path_fig, master=info_frame)
        path_canvas.get_tk_widget().pack(pady=10)
        path_display_visible = True
        update_path_dot_only()
    else:
        path_canvas.get_tk_widget().pack_forget()
        path_display_visible = False

def update_path_dot_only():
    if path_display_visible and path_ax:
        path_ax.clear()
        if real_world_path:
            x_vals, y_vals = zip(*real_world_path)
            path_ax.plot(x_vals, y_vals, label='Path')
        if real_world_red:
            path_ax.scatter(real_world_red[0], real_world_red[1], c='r', s=60, label='Ball')
        path_ax.set_title("Ball Path")
        path_ax.set_xlabel("X (cm)")
        path_ax.set_ylabel("Y (cm)")
        path_ax.legend()
        path_ax.grid(True)
        path_ax.axis('equal')
        path_canvas.draw()
    root.after(500, update_path_dot_only)

def plot_error_graph():
    try:
        duration = int(duration_entry.get())
        if not timestamps:
            messagebox.showwarning("æç¤º", "æ²¡æœ‰è¯¯å·®æ•°æ®ï¼")
            return

        current_time = time.time() - start_time
        target_start_time = current_time - duration

        x_vals = []
        y_vals = []

        for t, e in zip(timestamps, errors):
            if t >= target_start_time:
                x_vals.append(t - target_start_time)
                y_vals.append(e)

        if not x_vals:
            messagebox.showwarning("æç¤º", "æŒ‡å®šæ—¶é—´æ®µå†…æ— æ•°æ®")
            return

        plt.figure(figsize=(8, 4))
        plt.plot(x_vals, y_vals, marker='o')
        plt.title(f"Tracking Error (Last {duration} Seconds)")
        plt.xlabel("Time (s)")
        plt.ylabel("Error (cm)")
        plt.grid(True)
        plt.tight_layout()
        plt.show()

    except ValueError:
        messagebox.showerror("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„ç§’æ•°ï¼")

def stop_video():
    global video_running
    video_running = False

def video_loop():
    global video_capture, red_center, target_point, real_world_red

    video_capture = cv2.VideoCapture(0)
    while video_running:
        ret, frame = video_capture.read()
        if not ret:
            print("âš ï¸ æ— æ³•è¯»å–è§†é¢‘å¸§")
            break

        frame = cv2.flip(frame, 1)

        # æ¯å¸§åªæ‰¾çº¢çƒï¼Œä¸é‡æ–°æ‰¾è·¯å¾„
        red_center = detect_red_ball(frame)
        if red_center is not None:
            real_world_red = detect_aruco_and_map_red_ball(red_center, frame)

            if real_world_red:
                current_value.config(text=f"({real_world_red[0]:.2f}, {real_world_red[1]:.2f})")

                if real_world_path:
                    dists = [calculate_distance(real_world_red, pt) for pt in real_world_path]
                    min_idx = np.argmin(dists)
                    error_point = real_world_path[min_idx]   # æœ€è¿‘ç‚¹
                    error = dists[min_idx]

                    # æ‰¾é¢†å…ˆ30ä¸ªç‚¹ä½œä¸ºç›®æ ‡ç‚¹
                    target_idx = min(min_idx + headidx, len(real_world_path) - 1)
                    target_point = real_world_path[target_idx]

                    # æ˜¾ç¤ºä¸ä¿å­˜
                    target_value.config(text=f"({target_point[0]:.2f}, {target_point[1]:.2f})")
                    errors.append(error)
                    timestamps.append(time.time() - start_time)

                    # I2Cå‘é€
                    x1, y1 = int(real_world_red[0] * 10), int(real_world_red[1] * 10)
                    x2, y2 = int(target_point[0] * 10), int(target_point[1] * 10)
                    #send_two_points_16bit(x1, y1, x2, y2)

        # æ˜¾ç¤ºè§†é¢‘å¸§
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(rgb)
        imgtk = ImageTk.PhotoImage(image=img)
        panel.imgtk = imgtk
        panel.config(image=imgtk)

    video_capture.release()
    print("ğŸ¥ è§†é¢‘çº¿ç¨‹é€€å‡º")

def regenerate_path():
    global real_world_path, path_overlay, H
    if video_capture is not None:
        ret, frame = video_capture.read()
        if ret:
            path_overlay, red_center_, refined_path = generate_path_overlay(frame)
            get_aruco_centers(aruco_corners_dict)
            H = compute_homography_from_aruco(aruco_centers_dict, target_size=(22, 17))
            real_world_path = map_path_to_aruco_plane_coords(refined_path, H)
        else:
            messagebox.showwarning("æç¤º", "æ— æ³•ä»æ‘„åƒå¤´è¯»å–å›¾åƒå¸§ï¼")
    else:
        messagebox.showinfo("æç¤º", "è§†é¢‘æœªå¯åŠ¨ï¼Œè¯·å…ˆç‚¹å‡» Start")

def save_accuracy():
    if not errors or not timestamps:
        messagebox.showinfo("æç¤º", "æ²¡æœ‰å¯ä¿å­˜çš„è¯¯å·®æ•°æ®")
        return
    try:
        filename = time.strftime("accuracy_%Y%m%d_%H%M%S.csv")
        with open(filename, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(['Timestamp (s)', 'Error (cm)'])
            for t, e in zip(timestamps, errors):
                writer.writerow([t, e])
        messagebox.showinfo("ä¿å­˜æˆåŠŸ", f"å‡†ç¡®åº¦æ•°æ®å·²ä¿å­˜ä¸º {filename}")
    except Exception as e:
        messagebox.showerror("ä¿å­˜å¤±è´¥", str(e))


# ========== é€€å‡ºé’©å­ ==========
def on_closing():
    if messagebox.askokcancel("é€€å‡ºç¡®è®¤", "ç¡®å®šè¦é€€å‡ºç¨‹åºå—ï¼Ÿ"):
        global video_running
        video_running = False
        if video_capture:
            video_capture.release()
        root.destroy()

# ========== å¯åŠ¨ GUI ==========
root = tk.Tk()
root.title("çº¢çƒè¿½è¸ª GUI åˆå¹¶ç‰ˆ")
root.geometry("1280x720")

# å·¦ä¾§æŒ‰é’®æ 
control_frame = tk.Frame(root)
control_frame.pack(side="left", fill="y", padx=10, pady=10)

tk.Button(control_frame, text="â–¶ï¸ Start", width=20, height=2, command=start_video).pack(pady=5)
tk.Button(control_frame, text="â¹ï¸ Stop", width=20, height=2, command=stop_video).pack(pady=5)
tk.Button(control_frame, text="ğŸ” Re-generate Path", width=20, height=2, command=regenerate_path).pack(pady=5)
tk.Button(control_frame, text="ğŸ’¾ Save Accuracy", width=20, height=2, command=save_accuracy).pack(pady=5)

# å®æ—¶è¿è¡Œæ—¶é—´æ˜¾ç¤º
runtime_label = tk.Label(control_frame, text="è¿è¡Œæ—¶é—´:", font=("Arial", 12))
runtime_label.pack(pady=(30, 0))
runtime_value = tk.Label(control_frame, text="00:00:00", font=("Arial", 12), fg="purple")
runtime_value.pack()

# å®æ—¶è¯¯å·®å›¾æ—¶é—´æ®µè¾“å…¥æ¡†
tk.Label(control_frame, text="è¯¯å·®å›¾æ—¶é•¿ (ç§’):", font=("Arial", 12)).pack(pady=(20, 0))
duration_entry = tk.Entry(control_frame, width=10)
duration_entry.pack()
tk.Button(control_frame, text="ğŸ“ˆ ç”Ÿæˆè¯¯å·®å›¾", width=20, command=plot_error_graph).pack(pady=5)

# åŠ è½½è·¯å¾„ + å½“å‰ç‚¹åµŒå…¥æ˜¾ç¤ºå¼€å…³
tk.Button(control_frame, text="ğŸ“ æŸ¥çœ‹è·¯å¾„&å°çƒ", width=20, command=toggle_path_display).pack(pady=20)

# å³ä¾§ä¸»åŒºåŸŸï¼ŒåŒ…å«è§†é¢‘å’Œä¿¡æ¯é¢æ¿
right_frame = tk.Frame(root)
right_frame.pack(side="right", fill="both", expand=True)

# è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
video_frame = tk.Frame(right_frame)
video_frame.pack(side="left", fill="both", expand=True)

panel = tk.Label(video_frame)
panel.pack(fill="both", expand=True)

# åæ ‡æ˜¾ç¤ºåŒºåŸŸ
info_frame = tk.Frame(right_frame, bd=2, relief="groove")
info_frame.pack(side="right", padx=10, pady=10, fill="y")

tk.Label(info_frame, text="ğŸ¯ å½“å‰åæ ‡ (X, Y):", font=("Arial", 12)).grid(row=0, column=0, sticky="w")
current_value = tk.Label(info_frame, text="(0.00, 0.00)", font=("Arial", 12), fg="blue")
current_value.grid(row=0, column=1, sticky="w")

tk.Label(info_frame, text="ğŸ ç›®æ ‡åæ ‡ (X, Y):", font=("Arial", 12)).grid(row=1, column=0, sticky="w")
target_value = tk.Label(info_frame, text="(0.00, 0.00)", font=("Arial", 12), fg="green")
target_value.grid(row=1, column=1, sticky="w")

root.protocol("WM_DELETE_WINDOW", on_closing)
update_runtime()
root.mainloop()
