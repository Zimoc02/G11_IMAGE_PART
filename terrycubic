# -*- coding: utf-8 -*-
# Enhanced Predictive Path Following Version

import cv2
import numpy as np
import math
import smbus
from collections import deque
from scipy.spatial import cKDTree
from scipy.interpolate import splprep, splev

# ========== I2C Configuration ==========
bus = smbus.SMBus(1)
ARDUINO_ADDRESS = 0x08
NUM_FUTURE_POINTS = 3  # Number of future points to send
LOOK_AHEAD_DISTANCE = 80  # Pixels ahead for first target point

def int16_to_bytes(val):
    val = int(val)
    if val < 0:
        val = (1 << 16) + val
    return [(val >> 8) & 0xFF, val & 0xFF]

def send_path_points(points):
    """Send multiple path points through I2C"""
    data = []
    for point in points:
        y, x = point  # Convert from (row, col) to (x, y)
        data += int16_to_bytes(x) + int16_to_bytes(y)
    try:
        bus.write_i2c_block_data(ARDUINO_ADDRESS, 0x00, data)
        print(f"Sent {len(points)} points")
    except Exception as e:
        print(f"I2C Error: {e}")

# ========== Path Prediction Functions ==========
class PathPredictor:
    def __init__(self):
        self.path_points = []
        self.kdtree = None
        self.smooth_path = []
    
    def update_path(self, new_points):
        """Update path with new points (B-spline smoothed)"""
        if len(new_points) < 4:
            self.smooth_path = new_points
            return
        
        # B-spline interpolation
        path_array = np.array(new_points)
        y_points, x_points = path_array[:, 0], path_array[:, 1]
        tck, u = splprep([x_points, y_points], s=5, k=3)
        u_fine = np.linspace(0, 1, len(new_points) * 2)
        x_smooth, y_smooth = splev(u_fine, tck)
        
        self.smooth_path = [(y, x) for x, y in zip(x_smooth, y_smooth)]
        self.kdtree = cKDTree([(p[1], p[0]) for p in self.smooth_path])  # (x, y) format
    
    def get_future_points(self, current_pos, num_points=3):
        """Get future points along the path"""
        if not self.smooth_path or current_pos is None:
            return []
        
        # Convert to (x, y) format for KDTree
        current_xy = (current_pos[1], current_pos[0])
        
        # Find closest path point
        _, idx = self.kdtree.query(current_xy)
        
        # Get lookahead points
        future_points = []
        step_size = max(1, len(self.smooth_path) // 20)
        for i in range(num_points):
            target_idx = min(idx + (i+1)*step_size, len(self.smooth_path)-1)
            future_points.append(self.smooth_path[target_idx])
        
        return future_points

# ========== Enhanced Ball Tracking ==========
class BallTracker:
    def __init__(self):
        self.tracking_roi = None
        self.position_history = deque(maxlen=10)
        self.velocity = (0, 0)
    
    def detect_ball(self, frame):
        """Detect red ball with ROI optimization"""
        # ROI-based detection
        if self.tracking_roi:
            x, y, w, h = self.tracking_roi
            roi = frame[y:y+h, x:x+w]
            center = self._find_red_center(roi)
            if center:
                return (center[0]+y, center[1]+x)
        
        # Fallback to full-frame detection
        center = self._find_red_center(frame)
        if center:
            return center
        return None
    
    def _find_red_center(self, image):
        """Helper function for red detection"""
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        mask = cv2.bitwise_or(
            cv2.inRange(hsv, lower_red_1, upper_red_1),
            cv2.inRange(hsv, lower_red_2, upper_red_2)
        )
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        max_area = 0
        center = None
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area > 100 and area > max_area:
                (x, y), _ = cv2.minEnclosingCircle(cnt)
                center = (int(y), int(x))  # Return as (row, column)
                max_area = area
        return center

# ========== Main Processing Pipeline ==========
def main():
    # Initialize components
    path_predictor = PathPredictor()
    ball_tracker = BallTracker()
    
    # Camera setup
    cap = cv2.VideoCapture(
        "v4l2src device=/dev/video0 ! "
        "image/jpeg,width=1280,height=720,framerate=60/1 ! "
        "jpegdec ! videoconvert ! appsink",
        cv2.CAP_GSTREAMER
    )
    
    # Initial path generation
    ret, frame = cap.read()
    if not ret:
        print("Error: Cannot initialize camera")
        return
    
    # Generate initial path
    _, refined_path = generate_path_overlay(frame)
    path_predictor.update_path(refined_path)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Ball detection
        ball_pos = ball_tracker.detect_ball(frame)
        
        # Path following logic
        if ball_pos and path_predictor.smooth_path:
            # Get future points
            future_points = path_predictor.get_future_points(ball_pos, NUM_FUTURE_POINTS)
            
            # Send to Arduino
            if future_points:
                send_path_points(future_points)
            
            # Visualization
            for i, p in enumerate(future_points):
                cv2.circle(frame, (int(p[1]), int(p[0])), 8, (0, 0, 255), -1)
                cv2.putText(frame, str(i+1), (int(p[1])+10, int(p[0])+10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
        
        cv2.imshow("Tracking", frame)
        
        key = cv2.waitKey(1)
        if key == ord('q'):
            break
        elif key == ord('r'):  # Regenerate path
            _, refined_path = generate_path_overlay(frame)
            path_predictor.update_path(refined_path)
    
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
